{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283c92c2",
   "metadata": {},
   "source": [
    "# Discogs Electronic Recommender v10\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "This notebook builds a simple recommendation system using Discogs data.\n",
    "\n",
    "The goal is to:\n",
    "- Look at a my existing record collection and wantlist\n",
    "- Compare it against a wider catalogue of releases\n",
    "- Suggest new records that are musically similar\n",
    "\n",
    "The focus is **Electronic music only**, using metadata like genre, style, year, label, and artist relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917daf92",
   "metadata": {},
   "source": [
    "Set:\n",
    "\n",
    "- `DISCOGS_USER_TOKEN`\n",
    "- `DISCOGS_USERNAME`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b915",
   "metadata": {},
   "source": [
    "### Step 1: Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports & global config\n",
    "\n",
    "import os, time, math, random, re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14179c6e",
   "metadata": {},
   "source": [
    "This block prepares the Python environment for the rest of the notebook.\n",
    "\n",
    "It imports all required libraries used for:\n",
    "- Data manipulation (tables, arrays)\n",
    "- Database access\n",
    "- Text processing\n",
    "- Similarity calculations\n",
    "\n",
    "No data is loaded or modified here — this step simply makes sure\n",
    "all required tools are available before we begin. The tools that are being imported essentially do all of the statistical and mathmatical heavy lifting through the use of a few command lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc28264",
   "metadata": {},
   "source": [
    "### Step 2: Discogs API Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Discogs credentials ---\n",
    "DISCOGS_USER_TOKEN = os.getenv(\"DISCOGS_USER_TOKEN\", \"XXXX\")\n",
    "DISCOGS_USERNAME   = os.getenv(\"DISCOGS_USERNAME\",   \"XXXX\")\n",
    "\n",
    "assert DISCOGS_USER_TOKEN != \"REPLACE_WITH_YOUR_TOKEN\", \"Set DISCOGS_USER_TOKEN (env or edit cell).\"\n",
    "assert DISCOGS_USERNAME   != \"your_username_here\",      \"Set DISCOGS_USERNAME (env or edit cell).\"\n",
    "\n",
    "# --- API + rate limiting ---\n",
    "REQUESTS_PER_MIN      = 30\n",
    "SLEEP_BETWEEN_CALLS   = 60.0 / REQUESTS_PER_MIN\n",
    "MAX_RETRIES           = 7\n",
    "PER_PAGE              = 50\n",
    "TIMEOUT_S             = 40\n",
    "APP_UA                = f\"DiscogsRecommenderV8/1.0 (+https://www.discogs.com/user/{DISCOGS_USERNAME})\"\n",
    "\n",
    "print(\"Discogs user:\", DISCOGS_USERNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e3dab",
   "metadata": {},
   "source": [
    "This block defines the configuration used to communicate with the Discogs API.\n",
    "\n",
    "It includes:\n",
    "- API base URLs\n",
    "- Authentication headers\n",
    "- User agent information required by Discogs\n",
    "\n",
    "Centralising these values makes it easier to update credentials\n",
    "and ensures all API requests are made consistently.\n",
    "\n",
    "This block also ensures the script respects Discogs API rate limits.\n",
    "\n",
    "It introduces:\n",
    "- Controlled delays between requests\n",
    "- Conditional pauses when limits are approached\n",
    "\n",
    "Respecting rate limits prevents requests from being blocked\n",
    "and ensures long-running data pulls complete successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c49a8",
   "metadata": {},
   "source": [
    "### Step 3: API Request Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Low-level API helpers (retry + backoff)\n",
    "\n",
    "def _headers():\n",
    "    return {\n",
    "        \"User-Agent\": APP_UA,\n",
    "        \"Authorization\": f\"Discogs token={DISCOGS_USER_TOKEN}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "\n",
    "def _backoff(attempt: int, base: float = SLEEP_BETWEEN_CALLS, cap: float = 120.0) -> float:\n",
    "    return min(cap, base * (1.9 ** (attempt - 1))) + random.uniform(0, 0.9)\n",
    "\n",
    "def _raw_get(url: str, params: dict, what: str, page: int = 1):\n",
    "    \"\"\"GET with retries + simple exponential backoff.\"\"\"\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=_headers(), params=params, timeout=TIMEOUT_S)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                sleep_for = _backoff(attempt)\n",
    "                print(f\"[{what} retry {attempt}] page {page} HTTP {r.status_code}; sleep {sleep_for:.1f}s\")\n",
    "                time.sleep(sleep_for)\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except (requests.RequestException, JSONDecodeError) as e:\n",
    "            sleep_for = _backoff(attempt)\n",
    "            print(f\"[{what} retry {attempt}] page {page} {type(e).__name__}; sleep {sleep_for:.1f}s\")\n",
    "            time.sleep(sleep_for)\n",
    "    raise RuntimeError(f\"Failed to fetch {what} page {page} after {MAX_RETRIES} retries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0e103",
   "metadata": {},
   "source": [
    "This block adds retry and backoff logic to API calls.\n",
    "\n",
    "APIs can temporarily fail due to:\n",
    "- Rate limits\n",
    "- Network interruptions\n",
    "- Server-side timeouts\n",
    "\n",
    "When a request fails, this logic:\n",
    "- Waits for a short period\n",
    "- Gradually increases the wait time on repeated failures\n",
    "- Retries the request up to a defined limit\n",
    "\n",
    "This makes data collection more reliable and prevents\n",
    "the script from failing due to temporary issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde99dda",
   "metadata": {},
   "source": [
    "### Step 4: Helpers for parsing and normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helpers for parsing and normalisation\n",
    "\n",
    "def _to_str_list(x) -> List[str]:\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v) for v in x if isinstance(v, (str, int, float))]\n",
    "    return [str(x)]\n",
    "\n",
    "def _clean_name(name: str) -> str:\n",
    "    \"\"\"Strip Discogs cruft like 'Artist (2)' -> 'Artist'.\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    name = re.sub(r\"\\(\\d+\\)$\", \"\", name).strip()\n",
    "    return name\n",
    "\n",
    "def parse_year_value(y):\n",
    "    if y is None:\n",
    "        return None\n",
    "    if isinstance(y, (int, float)):\n",
    "        return int(y)\n",
    "    if isinstance(y, str):\n",
    "        m = re.search(r\"\\d{4}\", y)\n",
    "        return int(m.group(0)) if m else None\n",
    "    return None\n",
    "\n",
    "def year_bucket(year: Optional[int]) -> Optional[str]:\n",
    "    if year is None:\n",
    "        return None\n",
    "    return f\"year_{year}\"\n",
    "\n",
    "def norm_label(name: Optional[str]) -> Optional[str]:\n",
    "    if not isinstance(name, str):\n",
    "        return None\n",
    "    n = name.strip().lower()\n",
    "    return n or None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a4a04",
   "metadata": {},
   "source": [
    "This block defines helper functions used to parse and standardise\n",
    "raw Discogs metadata before it is stored or analysed.\n",
    "\n",
    "These helpers are responsible for:\n",
    "- Extracting values from nested or inconsistent API responses\n",
    "- Converting raw text into a consistent format\n",
    "- Normalising fields such as names, lists, and identifiers\n",
    "\n",
    "By centralising this logic, the rest of the pipeline can assume\n",
    "that incoming data is clean, predictable, and consistently structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7f6e7",
   "metadata": {},
   "source": [
    "### Step 5: Load in my Discogs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fetch collection + wantlist (with artist/label IDs)\n",
    "\n",
    "def _release_row_from_basic_info(bi: dict, source: str) -> Optional[dict]:\n",
    "    try:\n",
    "        artists_raw = bi.get(\"artists\") or []\n",
    "        labels_raw  = bi.get(\"labels\") or []\n",
    "\n",
    "        artists = [_clean_name(a.get(\"name\", \"\")) for a in artists_raw if isinstance(a, dict)]\n",
    "        artist_ids = [a.get(\"id\") for a in artists_raw if isinstance(a, dict) and a.get(\"id\")]\n",
    "\n",
    "        labels = [l.get(\"name\") for l in labels_raw if isinstance(l, dict)]\n",
    "        label_ids = [l.get(\"id\") for l in labels_raw if isinstance(l, dict) and l.get(\"id\")]\n",
    "\n",
    "        return {\n",
    "            \"release_id\": bi.get(\"id\"),\n",
    "            \"title\":      bi.get(\"title\"),\n",
    "            \"artists\":    artists,\n",
    "            \"artist_ids\": artist_ids,\n",
    "            \"labels\":     labels,\n",
    "            \"label_ids\":  label_ids,\n",
    "            \"genres\":     bi.get(\"genres\") or [],\n",
    "            \"styles\":     bi.get(\"styles\") or [],\n",
    "            \"year\":       parse_year_value(bi.get(\"year\")),\n",
    "            \"country\":    bi.get(\"country\"),\n",
    "            \"uri\":        bi.get(\"uri\"),\n",
    "            \"source\":     source,\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_collection() -> pd.DataFrame:\n",
    "    print(\"Fetching collection…\")\n",
    "    base = f\"https://api.discogs.com/users/{DISCOGS_USERNAME}/collection/folders/0/releases\"\n",
    "    page = 1\n",
    "    rows = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"page\": page, \"per_page\": PER_PAGE}\n",
    "        data = _raw_get(base, params, \"collection\", page)\n",
    "        for item in data.get(\"releases\", []):\n",
    "            bi = item.get(\"basic_information\") or {}\n",
    "            row = _release_row_from_basic_info(bi, source=\"collection\")\n",
    "            if row:\n",
    "                row[\"owned_qty\"] = item.get(\"basic_information\", {}).get(\"count\", 1)\n",
    "                rows.append(row)\n",
    "        pagination = data.get(\"pagination\") or {}\n",
    "        if page >= pagination.get(\"pages\", 1):\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Collection rows:\", len(df))\n",
    "    return df\n",
    "\n",
    "def fetch_wantlist() -> pd.DataFrame:\n",
    "    print(\"Fetching wantlist…\")\n",
    "    base = f\"https://api.discogs.com/users/{DISCOGS_USERNAME}/wants\"\n",
    "    page = 1\n",
    "    rows = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"page\": page, \"per_page\": PER_PAGE}\n",
    "        data = _raw_get(base, params, \"wantlist\", page)\n",
    "        for item in data.get(\"wants\", []):\n",
    "            bi = item.get(\"basic_information\") or {}\n",
    "            row = _release_row_from_basic_info(bi, source=\"wantlist\")\n",
    "            if row:\n",
    "                row[\"owned_qty\"] = 0\n",
    "                rows.append(row)\n",
    "        pagination = data.get(\"pagination\") or {}\n",
    "        if page >= pagination.get(\"pages\", 1):\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Wantlist rows:\", len(df))\n",
    "    return df\n",
    "\n",
    "df_collection = fetch_collection()\n",
    "df_wantlist   = fetch_wantlist()\n",
    "\n",
    "df_all = pd.concat([df_collection, df_wantlist], ignore_index=True).drop_duplicates(subset=[\"release_id\"])\n",
    "print(\"Total unique releases in profile:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1089d",
   "metadata": {},
   "source": [
    "This block queries the database and loads release-level data\n",
    "into a DataFrame (a table-like structure).\n",
    "\n",
    "Each row represents a single Discogs release, with columns\n",
    "containing metadata such as:\n",
    "- Release title\n",
    "- Artist name\n",
    "- Release year\n",
    "- Genre and style tags\n",
    "- Label identifiers\n",
    "\n",
    "At this stage, the data is raw and unfiltered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19780d",
   "metadata": {},
   "source": [
    "### Step 6: Establish baseline preference scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Base label & artist scores from your profile\n",
    "\n",
    "label_scores = defaultdict(float)     # key: normalised label name\n",
    "artist_scores = defaultdict(float)    # key: artist_id\n",
    "\n",
    "label_key_to_id = {}                  # norm label -> an example label_id\n",
    "label_key_to_name = {}                # norm label -> pretty label name\n",
    "artist_id_to_name = {}                # artist_id -> clean name\n",
    "\n",
    "for _, row in df_all.iterrows():\n",
    "    src = row.get(\"source\", \"collection\")\n",
    "    weight = 1.0 if src == \"collection\" else 1.7\n",
    "\n",
    "    for name in row.get(\"labels\", []) or []:\n",
    "        key = norm_label(name)\n",
    "        if not key:\n",
    "            continue\n",
    "        label_scores[key] += weight\n",
    "        label_key_to_name.setdefault(key, name)\n",
    "\n",
    "    artist_ids = row.get(\"artist_ids\") or []\n",
    "    artist_names = row.get(\"artists\") or []\n",
    "    for a_id, a_name in zip(artist_ids, artist_names):\n",
    "        if not a_id:\n",
    "            continue\n",
    "        artist_scores[a_id] += weight\n",
    "        artist_id_to_name[a_id] = _clean_name(a_name)\n",
    "\n",
    "    for name, lid in zip(row.get(\"labels\") or [], row.get(\"label_ids\") or []):\n",
    "        key = norm_label(name)\n",
    "        if key and lid and key not in label_key_to_id:\n",
    "            label_key_to_id[key] = lid\n",
    "\n",
    "print(\"Profile labels:\", len(label_scores), \" | Profile artists:\", len(artist_scores))\n",
    "display(pd.DataFrame(list(label_scores.items()), columns=[\"label_key\", \"score\"]).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdb6f5",
   "metadata": {},
   "source": [
    "This block builds baseline preference scores for labels and artists\n",
    "based on the my existing listening profile.\n",
    "\n",
    "It iterates over all known releases and:\n",
    "- Assigns higher weight to items from the user’s personal collection\n",
    "- Assigns lower (but still meaningful) weight to other known sources\n",
    "- Aggregates scores for labels and artists across all releases\n",
    "\n",
    "Label names are normalised to ensure consistent matching,\n",
    "while artist scores are tracked using unique artist IDs.\n",
    "\n",
    "The result is a weighted profile that captures which labels\n",
    "and artists appear most frequently in the user’s history,\n",
    "forming the foundation for later similarity and ranking steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdefee",
   "metadata": {},
   "source": [
    "### Step 7: Establish and expand label - parent/sub label relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1764da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding labels via parent/sub-label relationships\n",
    "\n",
    "def expand_labels_via_parent_sublabels(\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_id: Dict[str, int],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_seed_labels: int = 40,\n",
    "    rel_decay: float = 0.7,\n",
    ") -> None:\n",
    "    seed_items = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_seed_labels]\n",
    "\n",
    "    for key, base_score in tqdm(seed_items, desc=\"Parent/sublabel expansion\"):\n",
    "        lid = label_key_to_id.get(key)\n",
    "        if not lid:\n",
    "            continue\n",
    "        url = f\"https://api.discogs.com/labels/{lid}\"\n",
    "        data = _raw_get(url, {}, \"label_detail\", page=1)\n",
    "\n",
    "        parent = data.get(\"parent_label\")\n",
    "        if isinstance(parent, dict):\n",
    "            p_name = parent.get(\"name\")\n",
    "            pk = norm_label(p_name)\n",
    "            if pk:\n",
    "                label_scores[pk] += base_score * rel_decay\n",
    "                label_key_to_name.setdefault(pk, p_name)\n",
    "                if parent.get(\"id\") and pk not in label_key_to_id:\n",
    "                    label_key_to_id[pk] = parent.get(\"id\")\n",
    "\n",
    "        for sub in data.get(\"sublabels\") or []:\n",
    "            if not isinstance(sub, dict):\n",
    "                continue\n",
    "            s_name = sub.get(\"name\")\n",
    "            sk = norm_label(s_name)\n",
    "            if sk:\n",
    "                label_scores[sk] += base_score * rel_decay\n",
    "                label_key_to_name.setdefault(sk, s_name)\n",
    "                if sub.get(\"id\") and sk not in label_key_to_id:\n",
    "                    label_key_to_id[sk] = sub.get(\"id\")\n",
    "\n",
    "expand_labels_via_parent_sublabels(label_scores, label_key_to_id, label_key_to_name)\n",
    "print(\"Labels after parent/sub expansion:\", len(label_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dded89",
   "metadata": {},
   "source": [
    "This block expands the user’s label preference profile by leveraging\n",
    "Discogs parent and sub-label relationships.\n",
    "\n",
    "Starting from the user’s highest-scoring labels, the function:\n",
    "- Selects a limited set of top “seed” labels\n",
    "- Queries the Discogs API for each label’s hierarchy\n",
    "- Propagates preference scores to related parent and sub-labels\n",
    "\n",
    "Related labels receive a reduced score using a decay factor,\n",
    "reflecting indirect musical relevance rather than direct ownership.\n",
    "\n",
    "This allows the model to capture broader label ecosystems\n",
    "(e.g. imprints and parent organisations) without over-weighting them,\n",
    "resulting in a richer and more musically informed label profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040f3db",
   "metadata": {},
   "source": [
    "### Step 8: Expand preferences using artists other releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding labels via artists' other releases\n",
    "\n",
    "def expand_labels_via_artists_other_releases(\n",
    "    artist_scores: Dict[int, float],\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_artists: int = 60,\n",
    "    per_page: int = 50,\n",
    "    artist_to_label_decay: float = 0.6,\n",
    ") -> None:\n",
    "    top_artists = sorted(artist_scores.items(), key=lambda x: x[1], reverse=True)[:max_artists]\n",
    "\n",
    "    for a_id, a_score in tqdm(top_artists, desc=\"Label expansion via artists\"):\n",
    "        url = f\"https://api.discogs.com/artists/{a_id}/releases\"\n",
    "        params = {\"per_page\": per_page, \"page\": 1, \"sort\": \"year\"}\n",
    "        try:\n",
    "            data = _raw_get(url, params, \"artist_releases\", page=1)\n",
    "        except Exception as e:\n",
    "            print(\"Artist releases failed for\", a_id, \":\", e)\n",
    "            continue\n",
    "\n",
    "        for rel in data.get(\"releases\", []) or []:\n",
    "            label_str = rel.get(\"label\") or \"\"\n",
    "            labels = [p.strip() for p in label_str.split(\",\") if p.strip()]\n",
    "            for label_name in labels:\n",
    "                key = norm_label(label_name)\n",
    "                if not key:\n",
    "                    continue\n",
    "                label_scores[key] += a_score * artist_to_label_decay\n",
    "                label_key_to_name.setdefault(key, label_name)\n",
    "\n",
    "expand_labels_via_artists_other_releases(artist_scores, label_scores, label_key_to_name)\n",
    "print(\"Labels after artist-based expansion:\", len(label_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfce49",
   "metadata": {},
   "source": [
    "This block expands the label preference profile by exploring\n",
    "other releases from artists already associated with my taste.\n",
    "\n",
    "For each high-scoring artist, the function:\n",
    "- Queries the Discogs API for the artist’s full release history\n",
    "- Extracts label information from those releases\n",
    "- Adds weighted scores to any newly discovered labels\n",
    "\n",
    "Label scores inherited through artists are down-weighted using\n",
    "a decay factor, reflecting indirect influence rather than direct interaction.\n",
    "\n",
    "This approach captures the idea that electronic artists often release music\n",
    "across multiple labels, helping the model discover relevant labels\n",
    "that may not yet appear directly in the user’s collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347dc6bc",
   "metadata": {},
   "source": [
    "### Step 9: Expand artist preferences using labels (including parent and sub-labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding artists via labels (including parent/sub labels) other artists\n",
    "\n",
    "def expand_artists_via_labels(\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    artist_scores: Dict[int, float],\n",
    "    max_labels: int = 50,\n",
    "    pages_per_label: int = 1,\n",
    "    per_page: int = 50,\n",
    ") -> None:\n",
    "    base = \"https://api.discogs.com/database/search\"\n",
    "\n",
    "    sorted_labels = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_labels]\n",
    "\n",
    "    for key, score in tqdm(sorted_labels, desc=\"Artist expansion via labels\"):\n",
    "        label_name = label_key_to_name.get(key)\n",
    "        if not label_name:\n",
    "            continue\n",
    "\n",
    "        for page in range(1, pages_per_label + 1):\n",
    "            params = {\n",
    "                \"type\": \"release\",\n",
    "                \"label\": label_name,\n",
    "                \"genre\": \"Electronic\",\n",
    "                \"per_page\": per_page,\n",
    "                \"page\": page,\n",
    "            }\n",
    "            try:\n",
    "                _ = _raw_get(base, params, \"label_search_for_artists\", page=page)\n",
    "            except Exception as e:\n",
    "                print(\"Search failed for label\", label_name, \"page\", page, \":\", e)\n",
    "                break\n",
    "\n",
    "expand_artists_via_labels(label_scores, label_key_to_name, artist_scores)\n",
    "print(\"Artist expansion via labels complete (IDs boosted during enrichment).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06713dd",
   "metadata": {},
   "source": [
    "This block expands the artist preference profile by exploring\n",
    "other artists who release music on labels I already prefers.\n",
    "\n",
    "Starting from the highest-scoring labels, the function:\n",
    "- Searches the Discogs database for Electronic releases on each label\n",
    "- Identifies artists associated with those releases\n",
    "- Boosts artist relevance based on label association\n",
    "\n",
    "Because labels often curate a specific sound or scene,\n",
    "this approach helps surface artists who are stylistically aligned\n",
    "with my existing taste, even if they do not yet appear\n",
    "in my collection.\n",
    "\n",
    "Artist scores updated during this step are later used\n",
    "to improve recommendation coverage and discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc056a7",
   "metadata": {},
   "source": [
    "### Step 10: Search for candidates using label-seeded Discogs searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Build candidate releases via /database/search seeded by high-scoring labels\n",
    "\n",
    "def build_candidates_via_search_from_labels(\n",
    "    df_profile: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_label_seeds: int = 50,\n",
    "    pages_per_label: int = 2,   # upper bound; we'll stop earlier if Discogs says fewer pages\n",
    "    per_page: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    base = \"https://api.discogs.com/database/search\"\n",
    "    owned_ids = set(df_profile[\"release_id\"].tolist())\n",
    "    rows = []\n",
    "\n",
    "    sorted_labels = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_label_seeds]\n",
    "\n",
    "    for key, score in tqdm(sorted_labels, desc=\"Searching candidates by label\"):\n",
    "        label_name = label_key_to_name.get(key)\n",
    "        if not label_name:\n",
    "            continue\n",
    "\n",
    "        current_page = 1\n",
    "        max_pages_for_label = pages_per_label  # will be tightened after first response\n",
    "\n",
    "        while current_page <= max_pages_for_label:\n",
    "            params = {\n",
    "                \"type\": \"release\",\n",
    "                \"label\": label_name,\n",
    "                \"genre\": \"Electronic\",\n",
    "                \"per_page\": per_page,\n",
    "                \"page\": current_page,\n",
    "            }\n",
    "            try:\n",
    "                data = _raw_get(base, params, \"label_search_candidates\", page=current_page)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Search failed for label {label_name} page {current_page} : {e}\"\n",
    "                )\n",
    "                break  # give up on this label and move to the next one\n",
    "\n",
    "            # Use Discogs' own pagination to cap pages for this label\n",
    "            pagination = data.get(\"pagination\") or {}\n",
    "            total_pages = pagination.get(\"pages\") or 1\n",
    "            max_pages_for_label = min(pages_per_label, total_pages)\n",
    "\n",
    "            for item in (data.get(\"results\") or []):\n",
    "                rid = item.get(\"id\")\n",
    "                if not rid or rid in owned_ids:\n",
    "                    continue\n",
    "\n",
    "                # --- Artists: can be string or list ---\n",
    "                artist_field = item.get(\"artist\") or \"\"\n",
    "                if isinstance(artist_field, list):\n",
    "                    artist_pieces = artist_field\n",
    "                else:\n",
    "                    artist_pieces = re.split(r\",|&\", str(artist_field))\n",
    "\n",
    "                artists = [\n",
    "                    _clean_name(a)\n",
    "                    for a in artist_pieces\n",
    "                    if isinstance(a, str) and a.strip()\n",
    "                ]\n",
    "\n",
    "                # --- Labels: can be string or list ---\n",
    "                label_field = item.get(\"label\") or \"\"\n",
    "                label_pieces: List[str] = []\n",
    "\n",
    "                if isinstance(label_field, list):\n",
    "                    for v in label_field:\n",
    "                        if not isinstance(v, str):\n",
    "                            v = str(v)\n",
    "                        for part in v.split(\",\"):\n",
    "                            part = part.strip()\n",
    "                            if part:\n",
    "                                label_pieces.append(part)\n",
    "                elif isinstance(label_field, str):\n",
    "                    label_pieces = [s.strip() for s in label_field.split(\",\") if s.strip()]\n",
    "\n",
    "                labels = label_pieces\n",
    "\n",
    "                rows.append({\n",
    "                    \"release_id\": rid,\n",
    "                    \"title\": item.get(\"title\"),\n",
    "                    \"artists\": artists,\n",
    "                    \"artist_ids\": [],\n",
    "                    \"labels\": labels,\n",
    "                    \"genres\": _to_str_list(item.get(\"genre\")),\n",
    "                    \"styles\": _to_str_list(item.get(\"style\")),\n",
    "                    \"year\": parse_year_value(item.get(\"year\")),\n",
    "                    \"country\": item.get(\"country\"),\n",
    "                    \"uri\": item.get(\"uri\"),\n",
    "                    \"label_seed_key\": key,\n",
    "                    \"label_seed_score\": score,\n",
    "                })\n",
    "\n",
    "            current_page += 1\n",
    "\n",
    "    df_cand = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Raw candidates from label-seeded search:\", len(df_cand))\n",
    "    return df_cand\n",
    "\n",
    "df_candidates = build_candidates_via_search_from_labels(df_all, label_scores, label_key_to_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e8607",
   "metadata": {},
   "source": [
    "This block generates a pool of candidate releases by searching\n",
    "the Discogs database using the user’s highest-scoring labels as seeds.\n",
    "\n",
    "For each top label, the function:\n",
    "- Queries the Discogs search API for Electronic releases on that label\n",
    "- Handles paginated results to retrieve multiple pages when available\n",
    "- Skips releases already owned by the user\n",
    "- Parses and normalises artist, label, genre, and year metadata\n",
    "\n",
    "Each discovered release is stored along with information about\n",
    "which label it was sourced from and how strong that label’s score is.\n",
    "\n",
    "The output of this step is a broad but musically relevant candidate set\n",
    "that will later be filtered, scored, and ranked by the recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06f91f",
   "metadata": {},
   "source": [
    "### Step 11: Enrich candidate releases with full release details and refine artist preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Enrich candidates with /releases details + boost new artists via label affinity and pull have/want counts. Keep ONLY pure Electronic (genres == [\"Electronic\"]).\n",
    "\n",
    "def enrich_candidates_with_release_details(\n",
    "    df_cand: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    artist_scores: Dict[int, float],\n",
    "    max_details: int = 800,\n",
    ") -> (pd.DataFrame, Dict[int, float]):\n",
    "    if df_cand.empty:\n",
    "        return df_cand, artist_scores\n",
    "\n",
    "    artist_scores_ext = dict(artist_scores)\n",
    "    profile_artist_ids = set(artist_scores.keys())\n",
    "\n",
    "    rows = []\n",
    "    ids = df_cand[\"release_id\"].tolist()[:max_details]\n",
    "\n",
    "    for rid in tqdm(ids, desc=\"Enriching candidates\"):\n",
    "        url = f\"https://api.discogs.com/releases/{rid}\"\n",
    "        try:\n",
    "            data = _raw_get(url, {}, \"release_detail\", page=1)\n",
    "        except Exception as e:\n",
    "            print(\"Release detail failed for\", rid, \":\", e)\n",
    "            continue\n",
    "\n",
    "        genres = data.get(\"genres\") or []\n",
    "        # require pure Electronic only\n",
    "        if not genres or set(genres) != {\"Electronic\"}:\n",
    "            continue\n",
    "\n",
    "        styles = data.get(\"styles\") or []\n",
    "        country = data.get(\"country\")\n",
    "\n",
    "        artists_raw = data.get(\"artists\") or []\n",
    "        artists = []\n",
    "        artist_ids = []\n",
    "        for a in artists_raw:\n",
    "            if not isinstance(a, dict):\n",
    "                continue\n",
    "            nm = _clean_name(a.get(\"name\", \"\"))\n",
    "            aid = a.get(\"id\")\n",
    "            if nm:\n",
    "                artists.append(nm)\n",
    "            if aid:\n",
    "                artist_ids.append(aid)\n",
    "                artist_id_to_name.setdefault(aid, nm)\n",
    "\n",
    "        labels_raw = data.get(\"labels\") or []\n",
    "        labels = [lab.get(\"name\") for lab in labels_raw if isinstance(lab, dict) and lab.get(\"name\")]\n",
    "        label_keys = [norm_label(l) for l in labels if norm_label(l)]\n",
    "        max_label_affinity = max([label_scores.get(k, 0.0) for k in label_keys] or [0.0])\n",
    "\n",
    "        # boost NEW artists that appear on liked labels\n",
    "        for aid in artist_ids:\n",
    "            if aid not in profile_artist_ids:\n",
    "                artist_scores_ext[aid] = artist_scores_ext.get(aid, 0.0) + max_label_affinity * 0.5\n",
    "\n",
    "        community = data.get(\"community\") or {}\n",
    "        have_count = community.get(\"have\")\n",
    "        want_count = community.get(\"want\")\n",
    "\n",
    "        rows.append({\n",
    "            \"release_id\": rid,\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"artists\": artists,\n",
    "            \"artist_ids\": artist_ids,\n",
    "            \"labels\": labels,\n",
    "            \"genres\": genres,\n",
    "            \"styles\": styles,\n",
    "            \"year\": parse_year_value(data.get(\"year\")),\n",
    "            \"country\": country,\n",
    "            \"uri\": data.get(\"uri\") or data.get(\"resource_url\"),\n",
    "            \"have_count\": have_count,\n",
    "            \"want_count\": want_count,\n",
    "        })\n",
    "\n",
    "    df_enriched = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Pure Electronic candidates after enrichment:\", len(df_enriched))\n",
    "    return df_enriched, artist_scores_ext\n",
    "\n",
    "df_candidates_enriched, artist_scores_extended = enrich_candidates_with_release_details(\n",
    "    df_candidates,\n",
    "    label_scores,\n",
    "    artist_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbd19d",
   "metadata": {},
   "source": [
    "This block enriches candidate releases by fetching full release-level\n",
    "metadata from the Discogs API and applying stricter filtering rules.\n",
    "\n",
    "For each candidate release, the function:\n",
    "- Retrieves detailed release information from the Discogs `/releases` endpoint\n",
    "- Keeps only releases that are classified as **pure Electronic** (no mixed genres)\n",
    "- Extracts clean artist, label, style, year, and country metadata\n",
    "- Pulls community engagement signals (have / want counts)\n",
    "\n",
    "If a release appears on a label the user already prefers,\n",
    "new (previously unseen) artists on that release receive\n",
    "a small score boost based on label affinity.\n",
    "\n",
    "The output of this step is:\n",
    "- A refined set of high-quality Electronic candidates\n",
    "- An expanded artist score profile that incorporates label-based discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c48a5",
   "metadata": {},
   "source": [
    "### Step 12: Build Term Frequency - Inverse Document Frequency text features for releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434581e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Build TF-IDF text representation\n",
    "\n",
    "def build_release_text_features(df: pd.DataFrame) -> List[str]:\n",
    "    texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = []\n",
    "\n",
    "        for a in row.get(\"artists\", []) or []:\n",
    "            tokens.append(\"artist_\" + re.sub(r\"\\s+\", \"_\", _clean_name(str(a)).lower()))\n",
    "\n",
    "        for l in row.get(\"labels\", []) or []:\n",
    "            tokens.append(\"label_\" + re.sub(r\"\\s+\", \"_\", str(l).lower()))\n",
    "\n",
    "        for g in row.get(\"genres\", []) or []:\n",
    "            tokens.append(\"genre_\" + re.sub(r\"\\s+\", \"_\", str(g).lower()))\n",
    "\n",
    "        for s in row.get(\"styles\", []) or []:\n",
    "            tokens.append(\"style_\" + re.sub(r\"\\s+\", \"_\", str(s).lower()))\n",
    "\n",
    "        country = row.get(\"country\")\n",
    "        if isinstance(country, str) and country:\n",
    "            tokens.append(\"country_\" + re.sub(r\"\\s+\", \"_\", country.lower()))\n",
    "\n",
    "        y = row.get(\"year\")\n",
    "        yb = year_bucket(y)\n",
    "        if yb:\n",
    "            tokens.append(yb)\n",
    "\n",
    "        source = row.get(\"source\")\n",
    "        if isinstance(source, str):\n",
    "            tokens.append(\"source_\" + source.lower())\n",
    "\n",
    "        texts.append(\" \".join(tokens))\n",
    "    return texts\n",
    "\n",
    "mask_electronic_profile = df_all[\"genres\"].apply(lambda gs: (\"Electronic\" in (gs or [])) if isinstance(gs, list) else False)\n",
    "if mask_electronic_profile.any():\n",
    "    df_profile_vec = df_all[mask_electronic_profile].copy()\n",
    "else:\n",
    "    df_profile_vec = df_all.copy()\n",
    "\n",
    "df_profile_vec = df_profile_vec.reset_index(drop=True)\n",
    "df_cand_vec    = df_candidates_enriched.reset_index(drop=True)\n",
    "\n",
    "df_profile_vec[\"source\"] = df_profile_vec.get(\"source\", \"collection\")\n",
    "\n",
    "df_all_for_vector = pd.concat([\n",
    "    df_profile_vec.assign(kind=\"profile\"),\n",
    "    df_cand_vec.assign(kind=\"candidate\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "text_corpus = build_release_text_features(df_all_for_vector)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(text_corpus)\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n",
    "\n",
    "is_profile   = (df_all_for_vector[\"kind\"] == \"profile\").values\n",
    "is_candidate = (df_all_for_vector[\"kind\"] == \"candidate\").values\n",
    "\n",
    "X_profile   = X[is_profile]\n",
    "X_candidate = X[is_candidate]\n",
    "\n",
    "df_profile_vec = df_all_for_vector[is_profile].reset_index(drop=True)\n",
    "df_cand_vec    = df_all_for_vector[is_candidate].reset_index(drop=True)\n",
    "\n",
    "assert len(df_cand_vec) == len(df_candidates_enriched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421af19",
   "metadata": {},
   "source": [
    "This block converts musical metadata into a text-based representation\n",
    "that can be used for similarity calculations.\n",
    "\n",
    "For each release, the function:\n",
    "- Converts artists, labels, genres, styles, country, and era into text tokens\n",
    "- Adds prefixes (e.g. artist_, label_, style_) to preserve meaning\n",
    "- Groups release years into coarse time buckets\n",
    "- Combines all tokens into a single text string per release\n",
    "\n",
    "These text strings are then transformed into numerical vectors using\n",
    "TF-IDF (Term Frequency–Inverse Document Frequency), which highlights\n",
    "features that are distinctive rather than common across all releases.\n",
    "\n",
    "The resulting vector space is split into:\n",
    "- Profile vectors (the user’s existing releases)\n",
    "- Candidate vectors (potential recommendations)\n",
    "\n",
    "These vectors form the core input for the similarity model used\n",
    "to score and rank recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c9eb3",
   "metadata": {},
   "source": [
    "### Step 13: Add numeric affinity features for labels and artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Numeric features: label affinity, artist affinity (no ratings)\n",
    "\n",
    "def numeric_feature_matrix_for(\n",
    "    df: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    artist_scores_ext: Dict[int, float],\n",
    "):\n",
    "    label_aff = []\n",
    "    artist_aff = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        labels = row.get(\"labels\") or []\n",
    "        label_keys = [norm_label(l) for l in labels if norm_label(l)]\n",
    "        max_label_aff = max([label_scores.get(k, 0.0) for k in label_keys] or [0.0])\n",
    "        label_aff.append(max_label_aff)\n",
    "\n",
    "        artist_ids = row.get(\"artist_ids\") or []\n",
    "        max_artist_aff = max([artist_scores_ext.get(aid, 0.0) for aid in artist_ids] or [0.0])\n",
    "        artist_aff.append(max_artist_aff)\n",
    "\n",
    "    arr = np.vstack([\n",
    "        np.array(label_aff),\n",
    "        np.array(artist_aff),\n",
    "    ]).T\n",
    "    return arr\n",
    "\n",
    "num_profile = np.zeros((len(df_profile_vec), 2))\n",
    "num_cand    = numeric_feature_matrix_for(df_cand_vec, label_scores, artist_scores_extended)\n",
    "\n",
    "X_profile_full   = hstack([X_profile, num_profile])\n",
    "X_candidate_full = hstack([X_candidate, num_cand])\n",
    "\n",
    "print(\"Profile matrix (with numerics):\", X_profile_full.shape)\n",
    "print(\"Candidate matrix (with numerics):\", X_candidate_full.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f6bcf",
   "metadata": {},
   "source": [
    "This block adds simple numeric features that capture how closely\n",
    "each release aligns with the my preferred labels and artists.\n",
    "\n",
    "For each release, the function:\n",
    "- Looks up all associated labels and assigns the highest matching label score\n",
    "- Looks up all associated artists and assigns the highest matching artist score\n",
    "- Treats these values as continuous affinity signals rather than ratings\n",
    "\n",
    "These numeric features are then combined with the TF-IDF text vectors,\n",
    "creating a hybrid feature space that includes both:\n",
    "- Text-based similarity (metadata overlap)\n",
    "- Explicit preference strength (label and artist affinity)\n",
    "\n",
    "This helps the model favour releases that are not only textually similar,\n",
    "but also strongly connected to my established musical profile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fedd9",
   "metadata": {},
   "source": [
    "### Step 14: Score and rank candidate releases using similarity and community signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7377da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Score candidates with cosine similarity + have/want-based adjustments\n",
    "\n",
    "# Base taste vector\n",
    "user_vector = X_profile_full.mean(axis=0)\n",
    "user_vector = np.asarray(user_vector).reshape(1, -1)  # convert from np.matrix\n",
    "\n",
    "sims = cosine_similarity(X_candidate_full, user_vector)\n",
    "\n",
    "df_scored = df_candidates_enriched.copy()\n",
    "df_scored[\"base_score\"] = sims.ravel()\n",
    "\n",
    "# --- Have / want features ---\n",
    "have = df_scored[\"have_count\"].fillna(0).astype(float)\n",
    "want = df_scored[\"want_count\"].fillna(0).astype(float)\n",
    "\n",
    "# Desirability: favor high wants, low haves\n",
    "desirability = np.log1p(want) - np.log1p(have + 1.0)\n",
    "df_scored[\"desirability\"] = desirability\n",
    "\n",
    "# Penalty for well-known records (have > 500)\n",
    "overknown_penalty = (have > 500).astype(float)\n",
    "df_scored[\"overknown_penalty\"] = overknown_penalty\n",
    "\n",
    "# Combine:\n",
    "# - base_score from similarity\n",
    "# - positive contribution from desirability\n",
    "# - negative contribution from overknown_penalty\n",
    "df_scored[\"score\"] = (\n",
    "    df_scored[\"base_score\"]\n",
    "    + 0.25 * df_scored[\"desirability\"]\n",
    "    - 0.6 * df_scored[\"overknown_penalty\"]\n",
    ")\n",
    "\n",
    "df_scored = df_scored.sort_values(\n",
    "    by=[\"score\"],\n",
    "    ascending=[False],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Top scored candidates:\")\n",
    "display(df_scored[[\"release_id\", \"title\", \"artists\", \"labels\", \"score\", \"have_count\", \"want_count\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eda921",
   "metadata": {},
   "source": [
    "This block computes final recommendation scores for each candidate\n",
    "by combining musical similarity with Discogs community engagement data.\n",
    "\n",
    "First, a single “taste vector” is created by averaging my\n",
    "profile feature vectors. Each candidate release is then compared\n",
    "to this taste vector using cosine similarity, producing a base score.\n",
    "\n",
    "Next, community signals are incorporated:\n",
    "- Releases with high “want” counts are treated as more desirable\n",
    "- Releases with very high “have” counts are penalised to avoid\n",
    "  overly common or well-known records\n",
    "\n",
    "These signals are combined with the base similarity score using\n",
    "simple weighting rules to balance musical relevance with discovery.\n",
    "\n",
    "The final output is a ranked list of candidate releases, ordered\n",
    "from most to least recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e624e",
   "metadata": {},
   "source": [
    "### Step 15: Select final recommendations with diversity constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Final recommendations — Electronic only, one per artist + label\n",
    "\n",
    "def select_unique_recommendations(\n",
    "    df_scored: pd.DataFrame,\n",
    "    top_n: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    df = df_scored.copy()\n",
    "\n",
    "    # genres already pure Electronic, but keep check\n",
    "    df[\"is_electronic\"] = df[\"genres\"].apply(lambda gs: set(gs or []) == {\"Electronic\"})\n",
    "    df = df[df[\"is_electronic\"]].copy()\n",
    "\n",
    "    seen_artists = set()\n",
    "    seen_labels = set()\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        artists = [a.strip() for a in (row.get(\"artists\") or []) if isinstance(a, str)]\n",
    "        labels  = [l.strip() for l in (row.get(\"labels\") or []) if isinstance(l, str)]\n",
    "\n",
    "        main_artist = artists[0] if artists else None\n",
    "        main_label  = labels[0] if labels else None\n",
    "\n",
    "        if main_artist and main_artist in seen_artists:\n",
    "            continue\n",
    "        if main_label and main_label in seen_labels:\n",
    "            continue\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "        if main_artist:\n",
    "            seen_artists.add(main_artist)\n",
    "        if main_label:\n",
    "            seen_labels.add(main_label)\n",
    "\n",
    "        if len(rows) >= top_n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "final_recs = select_unique_recommendations(df_scored, top_n=50)\n",
    "\n",
    "print(\"Final Electronic recommendations:\", len(final_recs))\n",
    "cols_to_show = [\n",
    "    \"release_id\",\n",
    "    \"title\",\n",
    "    \"artists\",\n",
    "    \"labels\",\n",
    "    \"genres\",\n",
    "    \"styles\",\n",
    "    \"year\",\n",
    "    \"country\",\n",
    "    \"have_count\",\n",
    "    \"want_count\",\n",
    "    \"score\",\n",
    "    \"uri\",\n",
    "]\n",
    "display(final_recs[cols_to_show].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbff3e",
   "metadata": {},
   "source": [
    "This block produces the final recommendation list by applying\n",
    "diversity and quality constraints to the scored candidates.\n",
    "\n",
    "Although candidates have already been filtered, this step:\n",
    "- Re-confirms that all releases are **pure Electronic**\n",
    "- Limits results to one release per artist\n",
    "- Limits results to one release per label\n",
    "\n",
    "By enforcing these constraints, the output avoids clustering\n",
    "around a single artist or label and instead promotes broader\n",
    "musical discovery.\n",
    "\n",
    "The result is a balanced, high-quality recommendation list\n",
    "that prioritises variety while preserving relevance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
