{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283c92c2",
   "metadata": {},
   "source": [
    "# Discogs Electronic Recommender v8 — Graph + Search (No Label Paging)\n",
    "\n",
    "This version avoids unstable `/labels/{id}/releases` paging and instead:\n",
    "\n",
    "- Builds a **label/artist graph** from your collection + wantlist.\n",
    "- Expands labels via:\n",
    "  - **Parent / sub-label relationships**\n",
    "  - **Your artists' other releases**\n",
    "- Expands artists via:\n",
    "  - **Labels (including parent/sub labels) that you like**, by seeing which other artists appear.\n",
    "- Uses `/database/search` (label + genre=Electronic) to build a candidate pool.\n",
    "- Enriches candidates via `/releases/{id}`.\n",
    "- Scores using a **vector-space model (TF-IDF + cosine similarity)** + numeric features\n",
    "  (label affinity, artist affinity, ratings, votes).\n",
    "- Returns **Electronic-only** recommendations, one per artist + label.\n",
    "\n",
    "Set:\n",
    "\n",
    "- `DISCOGS_USER_TOKEN`\n",
    "- `DISCOGS_USERNAME`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports & global config\n",
    "\n",
    "import os, time, math, random, re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from json import JSONDecodeError\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- Discogs credentials ---\n",
    "DISCOGS_USER_TOKEN = os.getenv(\"DISCOGS_USER_TOKEN\", \"XXXX\")\n",
    "DISCOGS_USERNAME   = os.getenv(\"DISCOGS_USERNAME\",   \"XXXX\")\n",
    "\n",
    "assert DISCOGS_USER_TOKEN != \"REPLACE_WITH_YOUR_TOKEN\", \"Set DISCOGS_USER_TOKEN (env or edit cell).\"\n",
    "assert DISCOGS_USERNAME   != \"your_username_here\",      \"Set DISCOGS_USERNAME (env or edit cell).\"\n",
    "\n",
    "# --- API + rate limiting ---\n",
    "REQUESTS_PER_MIN      = 30\n",
    "SLEEP_BETWEEN_CALLS   = 60.0 / REQUESTS_PER_MIN\n",
    "MAX_RETRIES           = 7\n",
    "PER_PAGE              = 50\n",
    "TIMEOUT_S             = 40\n",
    "APP_UA                = f\"DiscogsRecommenderV8/1.0 (+https://www.discogs.com/user/{DISCOGS_USERNAME})\"\n",
    "\n",
    "print(\"Discogs user:\", DISCOGS_USERNAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Low-level API helpers (retry + backoff)\n",
    "\n",
    "def _headers():\n",
    "    return {\n",
    "        \"User-Agent\": APP_UA,\n",
    "        \"Authorization\": f\"Discogs token={DISCOGS_USER_TOKEN}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "\n",
    "def _backoff(attempt: int, base: float = SLEEP_BETWEEN_CALLS, cap: float = 120.0) -> float:\n",
    "    return min(cap, base * (1.9 ** (attempt - 1))) + random.uniform(0, 0.9)\n",
    "\n",
    "def _raw_get(url: str, params: dict, what: str, page: int = 1):\n",
    "    \"\"\"GET with retries + simple exponential backoff.\"\"\"\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=_headers(), params=params, timeout=TIMEOUT_S)\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                sleep_for = _backoff(attempt)\n",
    "                print(f\"[{what} retry {attempt}] page {page} HTTP {r.status_code}; sleep {sleep_for:.1f}s\")\n",
    "                time.sleep(sleep_for)\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except (requests.RequestException, JSONDecodeError) as e:\n",
    "            sleep_for = _backoff(attempt)\n",
    "            print(f\"[{what} retry {attempt}] page {page} {type(e).__name__}; sleep {sleep_for:.1f}s\")\n",
    "            time.sleep(sleep_for)\n",
    "    raise RuntimeError(f\"Failed to fetch {what} page {page} after {MAX_RETRIES} retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helpers for parsing and normalisation\n",
    "\n",
    "def _to_str_list(x) -> List[str]:\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v) for v in x if isinstance(v, (str, int, float))]\n",
    "    return [str(x)]\n",
    "\n",
    "def _clean_name(name: str) -> str:\n",
    "    \"\"\"Strip Discogs cruft like 'Artist (2)' -> 'Artist'.\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    name = re.sub(r\"\\(\\d+\\)$\", \"\", name).strip()\n",
    "    return name\n",
    "\n",
    "def parse_year_value(y):\n",
    "    if y is None:\n",
    "        return None\n",
    "    if isinstance(y, (int, float)):\n",
    "        return int(y)\n",
    "    if isinstance(y, str):\n",
    "        m = re.search(r\"\\d{4}\", y)\n",
    "        return int(m.group(0)) if m else None\n",
    "    return None\n",
    "\n",
    "def year_bucket(year: Optional[int]) -> Optional[str]:\n",
    "    if year is None:\n",
    "        return None\n",
    "    return f\"year_{year}\"\n",
    "\n",
    "def norm_label(name: Optional[str]) -> Optional[str]:\n",
    "    if not isinstance(name, str):\n",
    "        return None\n",
    "    n = name.strip().lower()\n",
    "    return n or None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fetch collection + wantlist (with artist/label IDs)\n",
    "\n",
    "def _release_row_from_basic_info(bi: dict, source: str) -> Optional[dict]:\n",
    "    try:\n",
    "        artists_raw = bi.get(\"artists\") or []\n",
    "        labels_raw  = bi.get(\"labels\") or []\n",
    "\n",
    "        artists = [_clean_name(a.get(\"name\", \"\")) for a in artists_raw if isinstance(a, dict)]\n",
    "        artist_ids = [a.get(\"id\") for a in artists_raw if isinstance(a, dict) and a.get(\"id\")]\n",
    "\n",
    "        labels = [l.get(\"name\") for l in labels_raw if isinstance(l, dict)]\n",
    "        label_ids = [l.get(\"id\") for l in labels_raw if isinstance(l, dict) and l.get(\"id\")]\n",
    "\n",
    "        return {\n",
    "            \"release_id\": bi.get(\"id\"),\n",
    "            \"title\":      bi.get(\"title\"),\n",
    "            \"artists\":    artists,\n",
    "            \"artist_ids\": artist_ids,\n",
    "            \"labels\":     labels,\n",
    "            \"label_ids\":  label_ids,\n",
    "            \"genres\":     bi.get(\"genres\") or [],\n",
    "            \"styles\":     bi.get(\"styles\") or [],\n",
    "            \"year\":       parse_year_value(bi.get(\"year\")),\n",
    "            \"country\":    bi.get(\"country\"),\n",
    "            \"uri\":        bi.get(\"uri\"),\n",
    "            \"source\":     source,\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_collection() -> pd.DataFrame:\n",
    "    print(\"Fetching collection…\")\n",
    "    base = f\"https://api.discogs.com/users/{DISCOGS_USERNAME}/collection/folders/0/releases\"\n",
    "    page = 1\n",
    "    rows = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"page\": page, \"per_page\": PER_PAGE}\n",
    "        data = _raw_get(base, params, \"collection\", page)\n",
    "        for item in data.get(\"releases\", []):\n",
    "            bi = item.get(\"basic_information\") or {}\n",
    "            row = _release_row_from_basic_info(bi, source=\"collection\")\n",
    "            if row:\n",
    "                row[\"owned_qty\"] = item.get(\"basic_information\", {}).get(\"count\", 1)\n",
    "                rows.append(row)\n",
    "        pagination = data.get(\"pagination\") or {}\n",
    "        if page >= pagination.get(\"pages\", 1):\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Collection rows:\", len(df))\n",
    "    return df\n",
    "\n",
    "def fetch_wantlist() -> pd.DataFrame:\n",
    "    print(\"Fetching wantlist…\")\n",
    "    base = f\"https://api.discogs.com/users/{DISCOGS_USERNAME}/wants\"\n",
    "    page = 1\n",
    "    rows = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"page\": page, \"per_page\": PER_PAGE}\n",
    "        data = _raw_get(base, params, \"wantlist\", page)\n",
    "        for item in data.get(\"wants\", []):\n",
    "            bi = item.get(\"basic_information\") or {}\n",
    "            row = _release_row_from_basic_info(bi, source=\"wantlist\")\n",
    "            if row:\n",
    "                row[\"owned_qty\"] = 0\n",
    "                rows.append(row)\n",
    "        pagination = data.get(\"pagination\") or {}\n",
    "        if page >= pagination.get(\"pages\", 1):\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Wantlist rows:\", len(df))\n",
    "    return df\n",
    "\n",
    "df_collection = fetch_collection()\n",
    "df_wantlist   = fetch_wantlist()\n",
    "\n",
    "df_all = pd.concat([df_collection, df_wantlist], ignore_index=True).drop_duplicates(subset=[\"release_id\"])\n",
    "print(\"Total unique releases in profile:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Base label & artist scores from your profile\n",
    "\n",
    "label_scores = defaultdict(float)     # key: normalised label name\n",
    "artist_scores = defaultdict(float)    # key: artist_id\n",
    "\n",
    "label_key_to_id = {}                  # norm label -> an example label_id\n",
    "label_key_to_name = {}                # norm label -> pretty label name\n",
    "artist_id_to_name = {}                # artist_id -> clean name\n",
    "\n",
    "for _, row in df_all.iterrows():\n",
    "    src = row.get(\"source\", \"collection\")\n",
    "    weight = 1.0 if src == \"collection\" else 1.7\n",
    "\n",
    "    for name in row.get(\"labels\", []) or []:\n",
    "        key = norm_label(name)\n",
    "        if not key:\n",
    "            continue\n",
    "        label_scores[key] += weight\n",
    "        label_key_to_name.setdefault(key, name)\n",
    "\n",
    "    artist_ids = row.get(\"artist_ids\") or []\n",
    "    artist_names = row.get(\"artists\") or []\n",
    "    for a_id, a_name in zip(artist_ids, artist_names):\n",
    "        if not a_id:\n",
    "            continue\n",
    "        artist_scores[a_id] += weight\n",
    "        artist_id_to_name[a_id] = _clean_name(a_name)\n",
    "\n",
    "    for name, lid in zip(row.get(\"labels\") or [], row.get(\"label_ids\") or []):\n",
    "        key = norm_label(name)\n",
    "        if key and lid and key not in label_key_to_id:\n",
    "            label_key_to_id[key] = lid\n",
    "\n",
    "print(\"Profile labels:\", len(label_scores), \" | Profile artists:\", len(artist_scores))\n",
    "display(pd.DataFrame(list(label_scores.items()), columns=[\"label_key\", \"score\"]).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1764da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding labels via parent/sub-label relationships\n",
    "\n",
    "def expand_labels_via_parent_sublabels(\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_id: Dict[str, int],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_seed_labels: int = 40,\n",
    "    rel_decay: float = 0.7,\n",
    ") -> None:\n",
    "    seed_items = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_seed_labels]\n",
    "\n",
    "    for key, base_score in tqdm(seed_items, desc=\"Parent/sublabel expansion\"):\n",
    "        lid = label_key_to_id.get(key)\n",
    "        if not lid:\n",
    "            continue\n",
    "        url = f\"https://api.discogs.com/labels/{lid}\"\n",
    "        data = _raw_get(url, {}, \"label_detail\", page=1)\n",
    "\n",
    "        parent = data.get(\"parent_label\")\n",
    "        if isinstance(parent, dict):\n",
    "            p_name = parent.get(\"name\")\n",
    "            pk = norm_label(p_name)\n",
    "            if pk:\n",
    "                label_scores[pk] += base_score * rel_decay\n",
    "                label_key_to_name.setdefault(pk, p_name)\n",
    "                if parent.get(\"id\") and pk not in label_key_to_id:\n",
    "                    label_key_to_id[pk] = parent.get(\"id\")\n",
    "\n",
    "        for sub in data.get(\"sublabels\") or []:\n",
    "            if not isinstance(sub, dict):\n",
    "                continue\n",
    "            s_name = sub.get(\"name\")\n",
    "            sk = norm_label(s_name)\n",
    "            if sk:\n",
    "                label_scores[sk] += base_score * rel_decay\n",
    "                label_key_to_name.setdefault(sk, s_name)\n",
    "                if sub.get(\"id\") and sk not in label_key_to_id:\n",
    "                    label_key_to_id[sk] = sub.get(\"id\")\n",
    "\n",
    "expand_labels_via_parent_sublabels(label_scores, label_key_to_id, label_key_to_name)\n",
    "print(\"Labels after parent/sub expansion:\", len(label_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding labels via artists' other releases\n",
    "\n",
    "def expand_labels_via_artists_other_releases(\n",
    "    artist_scores: Dict[int, float],\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_artists: int = 60,\n",
    "    per_page: int = 50,\n",
    "    artist_to_label_decay: float = 0.6,\n",
    ") -> None:\n",
    "    top_artists = sorted(artist_scores.items(), key=lambda x: x[1], reverse=True)[:max_artists]\n",
    "\n",
    "    for a_id, a_score in tqdm(top_artists, desc=\"Label expansion via artists\"):\n",
    "        url = f\"https://api.discogs.com/artists/{a_id}/releases\"\n",
    "        params = {\"per_page\": per_page, \"page\": 1, \"sort\": \"year\"}\n",
    "        try:\n",
    "            data = _raw_get(url, params, \"artist_releases\", page=1)\n",
    "        except Exception as e:\n",
    "            print(\"Artist releases failed for\", a_id, \":\", e)\n",
    "            continue\n",
    "\n",
    "        for rel in data.get(\"releases\", []) or []:\n",
    "            label_str = rel.get(\"label\") or \"\"\n",
    "            labels = [p.strip() for p in label_str.split(\",\") if p.strip()]\n",
    "            for label_name in labels:\n",
    "                key = norm_label(label_name)\n",
    "                if not key:\n",
    "                    continue\n",
    "                label_scores[key] += a_score * artist_to_label_decay\n",
    "                label_key_to_name.setdefault(key, label_name)\n",
    "\n",
    "expand_labels_via_artists_other_releases(artist_scores, label_scores, label_key_to_name)\n",
    "print(\"Labels after artist-based expansion:\", len(label_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Expanding artists via labels (including parent/sub labels) other artists\n",
    "\n",
    "def expand_artists_via_labels(\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    artist_scores: Dict[int, float],\n",
    "    max_labels: int = 50,\n",
    "    pages_per_label: int = 1,\n",
    "    per_page: int = 50,\n",
    ") -> None:\n",
    "    base = \"https://api.discogs.com/database/search\"\n",
    "\n",
    "    sorted_labels = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_labels]\n",
    "\n",
    "    for key, score in tqdm(sorted_labels, desc=\"Artist expansion via labels\"):\n",
    "        label_name = label_key_to_name.get(key)\n",
    "        if not label_name:\n",
    "            continue\n",
    "\n",
    "        for page in range(1, pages_per_label + 1):\n",
    "            params = {\n",
    "                \"type\": \"release\",\n",
    "                \"label\": label_name,\n",
    "                \"genre\": \"Electronic\",\n",
    "                \"per_page\": per_page,\n",
    "                \"page\": page,\n",
    "            }\n",
    "            try:\n",
    "                _ = _raw_get(base, params, \"label_search_for_artists\", page=page)\n",
    "            except Exception as e:\n",
    "                print(\"Search failed for label\", label_name, \"page\", page, \":\", e)\n",
    "                break\n",
    "\n",
    "expand_artists_via_labels(label_scores, label_key_to_name, artist_scores)\n",
    "print(\"Artist expansion via labels complete (IDs boosted during enrichment).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Build candidate releases via /database/search seeded by high-scoring labels\n",
    "\n",
    "def build_candidates_via_search_from_labels(\n",
    "    df_profile: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    label_key_to_name: Dict[str, str],\n",
    "    max_label_seeds: int = 50,\n",
    "    pages_per_label: int = 2,   # upper bound; we'll stop earlier if Discogs says fewer pages\n",
    "    per_page: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    base = \"https://api.discogs.com/database/search\"\n",
    "    owned_ids = set(df_profile[\"release_id\"].tolist())\n",
    "    rows = []\n",
    "\n",
    "    sorted_labels = sorted(label_scores.items(), key=lambda x: x[1], reverse=True)[:max_label_seeds]\n",
    "\n",
    "    for key, score in tqdm(sorted_labels, desc=\"Searching candidates by label\"):\n",
    "        label_name = label_key_to_name.get(key)\n",
    "        if not label_name:\n",
    "            continue\n",
    "\n",
    "        current_page = 1\n",
    "        max_pages_for_label = pages_per_label  # will be tightened after first response\n",
    "\n",
    "        while current_page <= max_pages_for_label:\n",
    "            params = {\n",
    "                \"type\": \"release\",\n",
    "                \"label\": label_name,\n",
    "                \"genre\": \"Electronic\",\n",
    "                \"per_page\": per_page,\n",
    "                \"page\": current_page,\n",
    "            }\n",
    "            try:\n",
    "                data = _raw_get(base, params, \"label_search_candidates\", page=current_page)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Search failed for label {label_name} page {current_page} : {e}\"\n",
    "                )\n",
    "                break  # give up on this label and move to the next one\n",
    "\n",
    "            # Use Discogs' own pagination to cap pages for this label\n",
    "            pagination = data.get(\"pagination\") or {}\n",
    "            total_pages = pagination.get(\"pages\") or 1\n",
    "            max_pages_for_label = min(pages_per_label, total_pages)\n",
    "\n",
    "            for item in (data.get(\"results\") or []):\n",
    "                rid = item.get(\"id\")\n",
    "                if not rid or rid in owned_ids:\n",
    "                    continue\n",
    "\n",
    "                # --- Artists: can be string or list ---\n",
    "                artist_field = item.get(\"artist\") or \"\"\n",
    "                if isinstance(artist_field, list):\n",
    "                    artist_pieces = artist_field\n",
    "                else:\n",
    "                    artist_pieces = re.split(r\",|&\", str(artist_field))\n",
    "\n",
    "                artists = [\n",
    "                    _clean_name(a)\n",
    "                    for a in artist_pieces\n",
    "                    if isinstance(a, str) and a.strip()\n",
    "                ]\n",
    "\n",
    "                # --- Labels: can be string or list ---\n",
    "                label_field = item.get(\"label\") or \"\"\n",
    "                label_pieces: List[str] = []\n",
    "\n",
    "                if isinstance(label_field, list):\n",
    "                    for v in label_field:\n",
    "                        if not isinstance(v, str):\n",
    "                            v = str(v)\n",
    "                        for part in v.split(\",\"):\n",
    "                            part = part.strip()\n",
    "                            if part:\n",
    "                                label_pieces.append(part)\n",
    "                elif isinstance(label_field, str):\n",
    "                    label_pieces = [s.strip() for s in label_field.split(\",\") if s.strip()]\n",
    "\n",
    "                labels = label_pieces\n",
    "\n",
    "                rows.append({\n",
    "                    \"release_id\": rid,\n",
    "                    \"title\": item.get(\"title\"),\n",
    "                    \"artists\": artists,\n",
    "                    \"artist_ids\": [],\n",
    "                    \"labels\": labels,\n",
    "                    \"genres\": _to_str_list(item.get(\"genre\")),\n",
    "                    \"styles\": _to_str_list(item.get(\"style\")),\n",
    "                    \"year\": parse_year_value(item.get(\"year\")),\n",
    "                    \"country\": item.get(\"country\"),\n",
    "                    \"uri\": item.get(\"uri\"),\n",
    "                    \"label_seed_key\": key,\n",
    "                    \"label_seed_score\": score,\n",
    "                })\n",
    "\n",
    "            current_page += 1\n",
    "\n",
    "    df_cand = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Raw candidates from label-seeded search:\", len(df_cand))\n",
    "    return df_cand\n",
    "\n",
    "df_candidates = build_candidates_via_search_from_labels(df_all, label_scores, label_key_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Enrich candidates with /releases details + boost new artists via label affinity\n",
    "#     and pull have/want counts. Keep ONLY pure Electronic (genres == [\"Electronic\"]).\n",
    "\n",
    "def enrich_candidates_with_release_details(\n",
    "    df_cand: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    artist_scores: Dict[int, float],\n",
    "    max_details: int = 800,\n",
    ") -> (pd.DataFrame, Dict[int, float]):\n",
    "    if df_cand.empty:\n",
    "        return df_cand, artist_scores\n",
    "\n",
    "    artist_scores_ext = dict(artist_scores)\n",
    "    profile_artist_ids = set(artist_scores.keys())\n",
    "\n",
    "    rows = []\n",
    "    ids = df_cand[\"release_id\"].tolist()[:max_details]\n",
    "\n",
    "    for rid in tqdm(ids, desc=\"Enriching candidates\"):\n",
    "        url = f\"https://api.discogs.com/releases/{rid}\"\n",
    "        try:\n",
    "            data = _raw_get(url, {}, \"release_detail\", page=1)\n",
    "        except Exception as e:\n",
    "            print(\"Release detail failed for\", rid, \":\", e)\n",
    "            continue\n",
    "\n",
    "        genres = data.get(\"genres\") or []\n",
    "        # require pure Electronic only\n",
    "        if not genres or set(genres) != {\"Electronic\"}:\n",
    "            continue\n",
    "\n",
    "        styles = data.get(\"styles\") or []\n",
    "        country = data.get(\"country\")\n",
    "\n",
    "        artists_raw = data.get(\"artists\") or []\n",
    "        artists = []\n",
    "        artist_ids = []\n",
    "        for a in artists_raw:\n",
    "            if not isinstance(a, dict):\n",
    "                continue\n",
    "            nm = _clean_name(a.get(\"name\", \"\"))\n",
    "            aid = a.get(\"id\")\n",
    "            if nm:\n",
    "                artists.append(nm)\n",
    "            if aid:\n",
    "                artist_ids.append(aid)\n",
    "                artist_id_to_name.setdefault(aid, nm)\n",
    "\n",
    "        labels_raw = data.get(\"labels\") or []\n",
    "        labels = [lab.get(\"name\") for lab in labels_raw if isinstance(lab, dict) and lab.get(\"name\")]\n",
    "        label_keys = [norm_label(l) for l in labels if norm_label(l)]\n",
    "        max_label_affinity = max([label_scores.get(k, 0.0) for k in label_keys] or [0.0])\n",
    "\n",
    "        # boost NEW artists that appear on liked labels\n",
    "        for aid in artist_ids:\n",
    "            if aid not in profile_artist_ids:\n",
    "                artist_scores_ext[aid] = artist_scores_ext.get(aid, 0.0) + max_label_affinity * 0.5\n",
    "\n",
    "        community = data.get(\"community\") or {}\n",
    "        have_count = community.get(\"have\")\n",
    "        want_count = community.get(\"want\")\n",
    "\n",
    "        rows.append({\n",
    "            \"release_id\": rid,\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"artists\": artists,\n",
    "            \"artist_ids\": artist_ids,\n",
    "            \"labels\": labels,\n",
    "            \"genres\": genres,\n",
    "            \"styles\": styles,\n",
    "            \"year\": parse_year_value(data.get(\"year\")),\n",
    "            \"country\": country,\n",
    "            \"uri\": data.get(\"uri\") or data.get(\"resource_url\"),\n",
    "            \"have_count\": have_count,\n",
    "            \"want_count\": want_count,\n",
    "        })\n",
    "\n",
    "    df_enriched = pd.DataFrame(rows).drop_duplicates(subset=[\"release_id\"])\n",
    "    print(\"Pure Electronic candidates after enrichment:\", len(df_enriched))\n",
    "    return df_enriched, artist_scores_ext\n",
    "\n",
    "df_candidates_enriched, artist_scores_extended = enrich_candidates_with_release_details(\n",
    "    df_candidates,\n",
    "    label_scores,\n",
    "    artist_scores,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434581e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Build TF-IDF text representation\n",
    "\n",
    "def build_release_text_features(df: pd.DataFrame) -> List[str]:\n",
    "    texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = []\n",
    "\n",
    "        for a in row.get(\"artists\", []) or []:\n",
    "            tokens.append(\"artist_\" + re.sub(r\"\\s+\", \"_\", _clean_name(str(a)).lower()))\n",
    "\n",
    "        for l in row.get(\"labels\", []) or []:\n",
    "            tokens.append(\"label_\" + re.sub(r\"\\s+\", \"_\", str(l).lower()))\n",
    "\n",
    "        for g in row.get(\"genres\", []) or []:\n",
    "            tokens.append(\"genre_\" + re.sub(r\"\\s+\", \"_\", str(g).lower()))\n",
    "\n",
    "        for s in row.get(\"styles\", []) or []:\n",
    "            tokens.append(\"style_\" + re.sub(r\"\\s+\", \"_\", str(s).lower()))\n",
    "\n",
    "        country = row.get(\"country\")\n",
    "        if isinstance(country, str) and country:\n",
    "            tokens.append(\"country_\" + re.sub(r\"\\s+\", \"_\", country.lower()))\n",
    "\n",
    "        y = row.get(\"year\")\n",
    "        yb = year_bucket(y)\n",
    "        if yb:\n",
    "            tokens.append(yb)\n",
    "\n",
    "        source = row.get(\"source\")\n",
    "        if isinstance(source, str):\n",
    "            tokens.append(\"source_\" + source.lower())\n",
    "\n",
    "        texts.append(\" \".join(tokens))\n",
    "    return texts\n",
    "\n",
    "mask_electronic_profile = df_all[\"genres\"].apply(lambda gs: (\"Electronic\" in (gs or [])) if isinstance(gs, list) else False)\n",
    "if mask_electronic_profile.any():\n",
    "    df_profile_vec = df_all[mask_electronic_profile].copy()\n",
    "else:\n",
    "    df_profile_vec = df_all.copy()\n",
    "\n",
    "df_profile_vec = df_profile_vec.reset_index(drop=True)\n",
    "df_cand_vec    = df_candidates_enriched.reset_index(drop=True)\n",
    "\n",
    "df_profile_vec[\"source\"] = df_profile_vec.get(\"source\", \"collection\")\n",
    "\n",
    "df_all_for_vector = pd.concat([\n",
    "    df_profile_vec.assign(kind=\"profile\"),\n",
    "    df_cand_vec.assign(kind=\"candidate\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "text_corpus = build_release_text_features(df_all_for_vector)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(text_corpus)\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n",
    "\n",
    "is_profile   = (df_all_for_vector[\"kind\"] == \"profile\").values\n",
    "is_candidate = (df_all_for_vector[\"kind\"] == \"candidate\").values\n",
    "\n",
    "X_profile   = X[is_profile]\n",
    "X_candidate = X[is_candidate]\n",
    "\n",
    "df_profile_vec = df_all_for_vector[is_profile].reset_index(drop=True)\n",
    "df_cand_vec    = df_all_for_vector[is_candidate].reset_index(drop=True)\n",
    "\n",
    "assert len(df_cand_vec) == len(df_candidates_enriched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Numeric features: label affinity, artist affinity (no ratings)\n",
    "\n",
    "def numeric_feature_matrix_for(\n",
    "    df: pd.DataFrame,\n",
    "    label_scores: Dict[str, float],\n",
    "    artist_scores_ext: Dict[int, float],\n",
    "):\n",
    "    label_aff = []\n",
    "    artist_aff = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        labels = row.get(\"labels\") or []\n",
    "        label_keys = [norm_label(l) for l in labels if norm_label(l)]\n",
    "        max_label_aff = max([label_scores.get(k, 0.0) for k in label_keys] or [0.0])\n",
    "        label_aff.append(max_label_aff)\n",
    "\n",
    "        artist_ids = row.get(\"artist_ids\") or []\n",
    "        max_artist_aff = max([artist_scores_ext.get(aid, 0.0) for aid in artist_ids] or [0.0])\n",
    "        artist_aff.append(max_artist_aff)\n",
    "\n",
    "    arr = np.vstack([\n",
    "        np.array(label_aff),\n",
    "        np.array(artist_aff),\n",
    "    ]).T\n",
    "    return arr\n",
    "\n",
    "num_profile = np.zeros((len(df_profile_vec), 2))\n",
    "num_cand    = numeric_feature_matrix_for(df_cand_vec, label_scores, artist_scores_extended)\n",
    "\n",
    "X_profile_full   = hstack([X_profile, num_profile])\n",
    "X_candidate_full = hstack([X_candidate, num_cand])\n",
    "\n",
    "print(\"Profile matrix (with numerics):\", X_profile_full.shape)\n",
    "print(\"Candidate matrix (with numerics):\", X_candidate_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7377da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Score candidates with cosine similarity + have/want-based adjustments\n",
    "\n",
    "# Base taste vector\n",
    "user_vector = X_profile_full.mean(axis=0)\n",
    "user_vector = np.asarray(user_vector).reshape(1, -1)  # convert from np.matrix\n",
    "\n",
    "sims = cosine_similarity(X_candidate_full, user_vector)\n",
    "\n",
    "df_scored = df_candidates_enriched.copy()\n",
    "df_scored[\"base_score\"] = sims.ravel()\n",
    "\n",
    "# --- Have / want features ---\n",
    "have = df_scored[\"have_count\"].fillna(0).astype(float)\n",
    "want = df_scored[\"want_count\"].fillna(0).astype(float)\n",
    "\n",
    "# Desirability: favor high wants, low haves\n",
    "desirability = np.log1p(want) - np.log1p(have + 1.0)\n",
    "df_scored[\"desirability\"] = desirability\n",
    "\n",
    "# Penalty for well-known records (have > 500)\n",
    "overknown_penalty = (have > 500).astype(float)\n",
    "df_scored[\"overknown_penalty\"] = overknown_penalty\n",
    "\n",
    "# Combine:\n",
    "# - base_score from similarity\n",
    "# - positive contribution from desirability\n",
    "# - negative contribution from overknown_penalty\n",
    "df_scored[\"score\"] = (\n",
    "    df_scored[\"base_score\"]\n",
    "    + 0.25 * df_scored[\"desirability\"]\n",
    "    - 0.6 * df_scored[\"overknown_penalty\"]\n",
    ")\n",
    "\n",
    "df_scored = df_scored.sort_values(\n",
    "    by=[\"score\"],\n",
    "    ascending=[False],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Top scored candidates:\")\n",
    "display(df_scored[[\"release_id\", \"title\", \"artists\", \"labels\", \"score\", \"have_count\", \"want_count\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Final recommendations — Electronic only, one per artist + label\n",
    "\n",
    "def select_unique_recommendations(\n",
    "    df_scored: pd.DataFrame,\n",
    "    top_n: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    df = df_scored.copy()\n",
    "\n",
    "    # genres already pure Electronic, but keep check\n",
    "    df[\"is_electronic\"] = df[\"genres\"].apply(lambda gs: set(gs or []) == {\"Electronic\"})\n",
    "    df = df[df[\"is_electronic\"]].copy()\n",
    "\n",
    "    seen_artists = set()\n",
    "    seen_labels = set()\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        artists = [a.strip() for a in (row.get(\"artists\") or []) if isinstance(a, str)]\n",
    "        labels  = [l.strip() for l in (row.get(\"labels\") or []) if isinstance(l, str)]\n",
    "\n",
    "        main_artist = artists[0] if artists else None\n",
    "        main_label  = labels[0] if labels else None\n",
    "\n",
    "        if main_artist and main_artist in seen_artists:\n",
    "            continue\n",
    "        if main_label and main_label in seen_labels:\n",
    "            continue\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "        if main_artist:\n",
    "            seen_artists.add(main_artist)\n",
    "        if main_label:\n",
    "            seen_labels.add(main_label)\n",
    "\n",
    "        if len(rows) >= top_n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "final_recs = select_unique_recommendations(df_scored, top_n=50)\n",
    "\n",
    "print(\"Final Electronic recommendations:\", len(final_recs))\n",
    "cols_to_show = [\n",
    "    \"release_id\",\n",
    "    \"title\",\n",
    "    \"artists\",\n",
    "    \"labels\",\n",
    "    \"genres\",\n",
    "    \"styles\",\n",
    "    \"year\",\n",
    "    \"country\",\n",
    "    \"have_count\",\n",
    "    \"want_count\",\n",
    "    \"score\",\n",
    "    \"uri\",\n",
    "]\n",
    "display(final_recs[cols_to_show].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Save recommendations to CSV\n",
    "\n",
    "out_path = Path(\"discogs_electronic_recommendations_v9_obscure.csv\")\n",
    "final_recs.to_csv(out_path, index=False)\n",
    "print(\"Saved recommendations to:\", out_path.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
